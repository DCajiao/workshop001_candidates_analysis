{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **First Step**: Consulting data to the Database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task:\n",
    "\n",
    "- Establish connection to the database\n",
    "- Load data into a data frame such as `df` for cleansing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Add the 'src' folder to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "from connections.db import DB\n",
    "\n",
    "db = DB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 20:08:10,130 - ✔ Connected to database\n",
      "2024-08-18 20:08:11,928 - ✔ Data loaded into DataFrame\n",
      "2024-08-18 20:08:11,931 - ✔ Cursor closed\n",
      "2024-08-18 20:08:11,932 - ✔ Connection closed\n"
     ]
    }
   ],
   "source": [
    "# Fetch the data from the database as a dataframe\n",
    "df = db.fetch_as_dataframe('../sql/queries/004_get_raw_data.sql')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Second Step**: Clean the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task:\n",
    "\n",
    "- Standardize column names.\n",
    "- Identify inconsistencies in data types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the names of the columns.\n",
    "df.columns = [col.lower() for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_name                   object\n",
       "last_name                    object\n",
       "email                        object\n",
       "application_date             object\n",
       "country                      object\n",
       "yoe                           int64\n",
       "seniority                    object\n",
       "technology                   object\n",
       "code_challenge_score          int64\n",
       "technical_interview_score     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check type of initial columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note:\n",
    ">\n",
    "> The `application_date` column must be of type datetime so that there is no confusion when making temporary queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['application_date'] = pd.to_datetime(df['application_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note:\n",
    ">\n",
    "> As we can see, the `application_date` column has been converted to the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_name                           object\n",
       "last_name                            object\n",
       "email                                object\n",
       "application_date             datetime64[ns]\n",
       "country                              object\n",
       "yoe                                   int64\n",
       "seniority                            object\n",
       "technology                           object\n",
       "code_challenge_score                  int64\n",
       "technical_interview_score             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: \n",
    ">\n",
    "> In the `technology` column we have many categories, as we saw in the notebook [01_data_exploration](https://github.com/DCajiao/workshop001_candidates_analysis/blob/develop/notebooks/01_data_exploration.ipynb), so I have decided to create a new column called `technology_topic` in order to generalize the categories and in the visualization stage to group them in a better way.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this way I will group the categories by topic:\n",
    "\n",
    "technology_topic = {\n",
    "    \"Development - Backend\" : \"Development\",\n",
    "    \"Development - FullStack\" : \"Development\",\n",
    "    \"Development - CMS Frontend\" : \"Development\",\n",
    "    \"Development - Frontend\" : \"Development\",\n",
    "    \"Development - CMS Backend\" : \"Development\",\n",
    "    \"DevOps\" : \"Development\",\n",
    "    \"Security\" : \"Security\",\n",
    "    \"Security Compliance\" : \"Security\",\n",
    "    \"QA Manual\" : \"QA\",\n",
    "    \"QA Automation\" : \"QA\",\n",
    "    \"Design\" : \"Design\",\n",
    "    \"Adobe Experience Manager\" : \"Design\",\n",
    "    \"Data Engineer\" : \"Data\",\n",
    "    \"Business Intelligence\" : \"Data\",\n",
    "    \"Database Administration\" : \"Data\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['technology_topic'] = df['technology'].map(technology_topic)\n",
    "df['technology_topic'] = df['technology_topic'].fillna(df['technology'])\n",
    "\n",
    "df = df[['first_name', 'last_name', 'email', 'application_date', 'country', 'yoe', 'seniority', 'technology', 'technology_topic', 'code_challenge_score', 'technical_interview_score']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Third Step**: Upload the data as a new clean table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task:\n",
    "\n",
    "- Define clean table scheme and save it in `sql/migrations/schema_clean.sql`.\n",
    "- Define the `sql/migrations/seed_data_clean.sql` to upload the data.\n",
    "- Run both queries to create a table and load the data into it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: \n",
    ">\n",
    "> I developed a class to get the `schema.sql` and `seed_data.sql` automatically from the dataframe.\n",
    ">\n",
    "> Check it out at [pysqlschema.py](https://github.com/DCajiao/workshop001_candidates_analysis/blob/develop/src/utils/pysqlschema.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 20:10:19,717 - Generating schema for candidates_cleaned\n",
      "2024-08-18 20:10:19,718 - Infering SQL type for object\n",
      "2024-08-18 20:10:19,719 - Infering SQL type for object\n",
      "2024-08-18 20:10:19,720 - Infering SQL type for object\n",
      "2024-08-18 20:10:19,721 - Infering SQL type for datetime64[ns]\n",
      "2024-08-18 20:10:19,722 - Infering SQL type for object\n",
      "2024-08-18 20:10:19,723 - Infering SQL type for int64\n",
      "2024-08-18 20:10:19,724 - Infering SQL type for object\n",
      "2024-08-18 20:10:19,724 - Infering SQL type for object\n",
      "2024-08-18 20:10:19,725 - Infering SQL type for object\n",
      "2024-08-18 20:10:19,726 - Infering SQL type for int64\n",
      "2024-08-18 20:10:19,727 - Infering SQL type for int64\n",
      "2024-08-18 20:10:19,729 - Query written to ../sql/migrations/schema_clean.sql\n",
      "2024-08-18 20:10:19,730 - Generating seed data for candidates_cleaned\n",
      "2024-08-18 20:10:23,630 - Query written to ../sql/migrations/seed_data_clean.sql\n"
     ]
    }
   ],
   "source": [
    "from utils.pysqlschema import SQLSchemaGenerator\n",
    "\n",
    "generator = SQLSchemaGenerator(table_name='candidates_cleaned')\n",
    "generator.generate_schema(df, '../sql/migrations/schema_clean.sql')\n",
    "generator.generate_seed_data(df, '../sql/migrations/seed_data_clean.sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 20:11:39,943 - ✔ Connected to database\n",
      "2024-08-18 20:11:53,041 - ✔ Query executed\n",
      "2024-08-18 20:11:53,042 - ✔ Cursor closed\n",
      "2024-08-18 20:11:53,044 - ✔ Connection closed\n"
     ]
    }
   ],
   "source": [
    "# Create schema\n",
    "db.execute(\"../sql/migrations/seed_data_clean.sql\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 20:11:13,666 - ✔ Connected to database\n",
      "2024-08-18 20:11:27,313 - ✔ Query executed\n",
      "2024-08-18 20:11:27,313 - ✔ Cursor closed\n",
      "2024-08-18 20:11:27,315 - ✔ Connection closed\n"
     ]
    }
   ],
   "source": [
    "# Seed data\n",
    "db.execute(\"../sql/migrations/seed_data_clean.sql\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 20:12:48,196 - ✔ Connected to database\n",
      "2024-08-18 20:12:48,776 - ✔ Query executed\n",
      "2024-08-18 20:12:48,776 - ✔ Cursor closed\n",
      "2024-08-18 20:12:48,777 - ✔ Connection closed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('candidates_cleaned',), ('candidates',)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the data was inserted correctly\n",
    "db.execute(\"../sql/queries/001_view_tables.sql\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 20:12:52,601 - ✔ Connected to database\n",
      "2024-08-18 20:12:53,143 - ✔ Query executed\n",
      "2024-08-18 20:12:53,143 - ✔ Cursor closed\n",
      "2024-08-18 20:12:53,144 - ✔ Connection closed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('public.candidates_cleaned', 50000), ('public.candidates', 50000)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size of the tables\n",
    "db.execute(\"../sql/queries/003_view_tables_sizes.sql\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Results**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The raw data has been consulted and loaded as a dataframe.\n",
    "- Column names have been standardized.\n",
    "- The `application_date` column has been correctly formatted as a datetime column.\n",
    "- Added 'technology_topic' column to be able to group 'technology' categories in future graphs\n",
    "- A new `schema` and `seed_data` has been generated automatically based on the clean df, using [pysqlschema.py](https://github.com/DCajiao/workshop001_candidates_analysis/blob/develop/src/utils/pysqlschema.py) and saved to `sql/migrations/`\n",
    "- The clean data table has been created in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
